{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(5976479, 3)\n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ratings.csv\")\n",
    "books = {}\n",
    "book_list = []\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "    book = df.loc[i,'book_id']\n",
    "    user = df.loc[i,'user_id']\n",
    "    if book not in books:\n",
    "        books[book] = []\n",
    "    books[book].append(user)\n",
    "for key, val in books.items():\n",
    "    book_list.append((key,val))\n",
    "\n",
    "ofile = open('out.csv',\"w+\")\n",
    "for i in range(0,len(book_list)-1):\n",
    "    for j in range(i+1,len(book_list)):\n",
    "        b1 = book_list[i][0]\n",
    "        b2 = book_list[j][0]\n",
    "        common_users = list(set(book_list[i][1]) & set(book_list[j][1]))\n",
    "        count = len(common_users)\n",
    "        line = str(b1) + ',' + str(b2) + ',' + str(count) + '\\n'\n",
    "        ofile.write(line)\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libaries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "from itertools import islice\n",
    "from pyspark.sql.functions import col\n",
    "#creating the context\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#reading the csv file into an RDD\n",
    "#r = sc.textFile(\"s3n://goodbooks-10k/data/ratings.csv\").map(lambda line: line.split(\",\"))\n",
    "#b = sc.textFile(\"s3n://goodbooks-10k/data/books.csv\").map(lambda line: line.split(\",\"))\n",
    "#bt = sc.textFile(\"s3n://goodbooks-10k/data/book_tags.csv\").map(lambda line: line.split(\",\"))\n",
    "#t = sc.textFile(\"s3n://goodbooks-10k/data/tags.csv\").map(lambda line: line.split(\",\"))\n",
    "#tr = sc.textFile(\"s3n://goodbooks-10k/data/to_read.csv\").map(lambda line: line.split(\",\"))\n",
    "\n",
    "#reading the csv file directly into a Pandas dataFrame\n",
    "# and remove duplicates\n",
    "b = spark.read.csv(\"s3n://goodbooks-10k/data/books.csv\", escape='\"', multiLine=True,\n",
    "     inferSchema=False, header=True).dropDuplicates()\n",
    "r = spark.read.csv(\"s3n://goodbooks-10k/data/ratings.csv\", escape='\"', multiLine=True,\n",
    "     inferSchema=False, header=True).dropDuplicates()\n",
    "bt = spark.read.csv(\"s3n://goodbooks-10k/data/book_tags.csv\", escape='\"', multiLine=True,\n",
    "     inferSchema=False, header=True).dropDuplicates()\n",
    "t = spark.read.csv(\"s3n://goodbooks-10k/data/tags.csv\", escape='\"', multiLine=True,\n",
    "     inferSchema=False, header=True).dropDuplicates()\n",
    "tr = spark.read.csv(\"s3n://goodbooks-10k/data/to_read.csv\", escape='\"', multiLine=True,\n",
    "     inferSchema=False, header=True).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find books that appear most often in TO-READ shelf\n",
    "tr_c = tr.groupBy(\"book_id\").count()\n",
    "tr_b = tr_c.join(b, on=\"book_id\").select(\"book_id\",\"authors\",\"title\",'original_publication_year','average_rating','image_url','small_image_url','count')\n",
    "tr_b = tr_b.sort(desc(\"count\"))\n",
    "tr_b.coalesce(1).write.csv('s3n://goodbooks-10k/output/to_read_count',header = 'true')\n",
    "tr_b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of tags for \"unfinished\"\n",
    "L = ['left-unfinished\\r','series-unfinished\\r','unfinished\\r','unfinished-abandoned\\r',\\\n",
    "    'unfinished-books\\r','unfinished-series\\r','unifinished\\r','incomplete\\r','half-read\\r']\n",
    "uf_tags = t.filter(col('tag_name\\r').isin(L))\n",
    "# Count number of times books are marked \"unifinished\"\n",
    "from pyspark.sql.types import IntegerType\n",
    "# join book_tags with list of unfinished tags\n",
    "uf_books = bt.join(uf_tags,on='tag_id').select('goodreads_book_id','count\\r','tag_name\\r')\n",
    "uf_books = uf_books.withColumn('count', regexp_replace('count\\r',\"\\r\",\"\"))\n",
    "uf_books = uf_books.withColumn('count', uf_books['count'].cast(IntegerType()))\n",
    "# sum all unfinished tags for each book\n",
    "uf_books= uf_books.groupBy('goodreads_book_id').sum('count')\n",
    "# Get book details\n",
    "uf_books = uf_books.join(b, on=\"goodreads_book_id\").select(\"book_id\",\"authors\",\"title\",\"sum(count)\",'image_url','small_image_url')\n",
    "uf_books = uf_books.sort(desc(\"sum(count)\"))\n",
    "uf_books.coalesce(1).write.csv('s3n://goodbooks-10k/output/unfinished_books',header = 'true')\n",
    "uf_books.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books with highest rating variance\n",
    "r_variance = r.groupBy('book_id').agg({'rating': 'variance'}).withColumnRenamed(\"variance(rating)\", \"variance\")\n",
    "r_variance = r_variance.join(b, on=\"book_id\").select(\"book_id\",\"authors\",\"title\",\"variance\",\"average_rating\")\n",
    "r_variance = r_variance.sort(desc(\"variance\"))\n",
    "r_variance.coalesce(1).write.csv('s3n://goodbooks-10k/output/controversial_books',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of tags for \"boring\"\n",
    "L = ['boring\\r','boring-characters\\r','just-boring\\r','kinda-boring\\r',\\\n",
    "    'bored-halfway-through\\r']\n",
    "boring_tags = t.filter(col('tag_name\\r').isin(L))\n",
    "# Count number of times books are marked \"boring\"\n",
    "from pyspark.sql.types import IntegerType\n",
    "# join book_tags with list of unfinished tags\n",
    "boring = bt.join(boring_tags,on='tag_id').select('goodreads_book_id','count\\r','tag_name\\r')\n",
    "boring = boring.withColumn('count', regexp_replace('count\\r',\"\\r\",\"\"))\n",
    "boring = boring.withColumn('count', boring['count'].cast(IntegerType()))\n",
    "# sum all unfinished tags for each book\n",
    "boring= boring.groupBy('goodreads_book_id').sum('count')\n",
    "# Get book details\n",
    "boring = boring.join(b, on=\"goodreads_book_id\").select(\"book_id\",\"authors\",\"title\",\"sum(count)\",'image_url','small_image_url')\n",
    "boring = boring.sort(desc(\"sum(count)\"))\n",
    "boring.coalesce(1).write.csv('s3n://goodbooks-10k/output/boring_books',header = 'true')\n",
    "boring.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most prolific writers\n",
    "author_works = b.groupBy(\"authors\").agg(count('*'),sum('ratings_count'),avg('average_rating'),sum('ratings_5'),sum('ratings_4'))\n",
    "author_works= author_works.sort(desc(\"count(1)\"))\n",
    "author_works.coalesce(1).write.csv('s3n://goodbooks-10k/output/authors',header = 'true')\n",
    "author_works.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most reviewed books and their averaged ratings\n",
    "r_count = r.groupBy('book_id').count()\n",
    "r_count = r_count.join(b, on=\"book_id\").select(\"book_id\",\"authors\",\"title\",\"count\",\"average_rating\")\n",
    "r_count = r_count.sort(desc(\"count\"))\n",
    "#r_count.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitanalysisconda560f4d48401e46e0aeb16a6b36b69737",
   "display_name": "Python 3.8.2 64-bit ('analysis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}